{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construction des fichiers pour la définition du pipeline de processing textuel\n",
    "\n",
    "Ce notebook permet d'assembler les fichiers text_process.csv des datasets 1, 3 et 4 en un fichier qui nous servira pour la définition du pipeline de processing textuel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/dhryniewski/DataScientest/doc-classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/dhryniewski/DataScientest/doc-classifier/.venv/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "current_dir = %pwd\n",
    "project_dir = os.path.dirname(current_dir)\n",
    "%cd $project_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans le dossier \"data\", nous allons créer un dossier \"processed\" dans lequel nous stockerons les fichiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder already exists: 'data/processed'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2597627/3233540087.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "if not os.path.exists(\"data/processed\"):\n",
    "    os.makedirs(\"data/processed\")\n",
    "    print(f\"Folder created: 'data/processed'\")\n",
    "else:\n",
    "    print(f\"Folder already exists: 'data/processed'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce code permet de concaténer les 3 fichiers text_process.csv en ajoutant la colonne 'data' pour avoir le jeu de données d'origine des images.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>lang</th>\n",
       "      <th>lang_score</th>\n",
       "      <th>file_name</th>\n",
       "      <th>category</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hazleton laboratory anerca fmc inuoioe ohon mi...</td>\n",
       "      <td>en</td>\n",
       "      <td>0.857141</td>\n",
       "      <td>image_0000297</td>\n",
       "      <td>invoice</td>\n",
       "      <td>data_01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ragnar rylander invoice consultant fee travel ...</td>\n",
       "      <td>en</td>\n",
       "      <td>0.857138</td>\n",
       "      <td>image_0000313</td>\n",
       "      <td>invoice</td>\n",
       "      <td>data_01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>please remit box chicago invoice invoice date ...</td>\n",
       "      <td>en</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>image_0000505</td>\n",
       "      <td>invoice</td>\n",
       "      <td>data_01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>purchase requisition originator copt sheet rtf...</td>\n",
       "      <td>en</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>image_0000269</td>\n",
       "      <td>invoice</td>\n",
       "      <td>data_01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hbi healthy building international inc covingt...</td>\n",
       "      <td>en</td>\n",
       "      <td>0.999995</td>\n",
       "      <td>image_0000020</td>\n",
       "      <td>invoice</td>\n",
       "      <td>data_01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               words lang  lang_score  \\\n",
       "0  hazleton laboratory anerca fmc inuoioe ohon mi...   en    0.857141   \n",
       "1  ragnar rylander invoice consultant fee travel ...   en    0.857138   \n",
       "2  please remit box chicago invoice invoice date ...   en    0.999994   \n",
       "3  purchase requisition originator copt sheet rtf...   en    0.999995   \n",
       "4  hbi healthy building international inc covingt...   en    0.999995   \n",
       "\n",
       "       file_name category     data  \n",
       "0  image_0000297  invoice  data_01  \n",
       "1  image_0000313  invoice  data_01  \n",
       "2  image_0000505  invoice  data_01  \n",
       "3  image_0000269  invoice  data_01  \n",
       "4  image_0000020  invoice  data_01  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li = []\n",
    "\n",
    "for i in [\"data_01\", \"data_03\", \"data_04\"]:\n",
    "    df = pd.read_csv(f\"data/raw/{i}/text_process.csv\")\n",
    "    df['data'] = i\n",
    "    li.append(df)\n",
    "\n",
    "frame_words = pd.concat(li, axis=0, ignore_index=True)\n",
    "frame_words.to_csv(\"data/processed/words.csv\", index=False)\n",
    "\n",
    "frame_words.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce code permet de concaténer les 3 fichiers text_process.csv ne gardant que les colonnes 'words' et 'category' et en ajoutant la colonne 'count' qui correspond au nombre de mots dans le text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>count</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hazleton laboratory anerca fmc inuoioe ohon mi...</td>\n",
       "      <td>76</td>\n",
       "      <td>invoice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ragnar rylander invoice consultant fee travel ...</td>\n",
       "      <td>12</td>\n",
       "      <td>invoice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>please remit box chicago invoice invoice date ...</td>\n",
       "      <td>105</td>\n",
       "      <td>invoice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>purchase requisition originator copt sheet rtf...</td>\n",
       "      <td>138</td>\n",
       "      <td>invoice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hbi healthy building international inc covingt...</td>\n",
       "      <td>69</td>\n",
       "      <td>invoice</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               words  count category\n",
       "0  hazleton laboratory anerca fmc inuoioe ohon mi...     76  invoice\n",
       "1  ragnar rylander invoice consultant fee travel ...     12  invoice\n",
       "2  please remit box chicago invoice invoice date ...    105  invoice\n",
       "3  purchase requisition originator copt sheet rtf...    138  invoice\n",
       "4  hbi healthy building international inc covingt...     69  invoice"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "li = []\n",
    "for i in [\"data_01\", \"data_03\", \"data_04\"]:\n",
    "    df = pd.read_csv(f\"data/raw/{i}/text_process.csv\",\n",
    "                     usecols=['words', 'category'])\n",
    "    df['words'] = df['words'].fillna('')\n",
    "    df.insert(loc=1, column='count', value=df['words'].apply(\n",
    "        lambda x: len(x.split())))\n",
    "    li.append(df)\n",
    "\n",
    "frame_count = pd.concat(li, axis=0, ignore_index=True)\n",
    "#frame_count.to_csv(\"data/processed/count_words.csv\", index=False)\n",
    "frame_count.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sélection des catégories définies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>count</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hazleton laboratory anerca fmc inuoioe ohon mi...</td>\n",
       "      <td>76</td>\n",
       "      <td>invoice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ragnar rylander invoice consultant fee travel ...</td>\n",
       "      <td>12</td>\n",
       "      <td>invoice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>please remit box chicago invoice invoice date ...</td>\n",
       "      <td>105</td>\n",
       "      <td>invoice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>purchase requisition originator copt sheet rtf...</td>\n",
       "      <td>138</td>\n",
       "      <td>invoice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hbi healthy building international inc covingt...</td>\n",
       "      <td>69</td>\n",
       "      <td>invoice</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7104</th>\n",
       "      <td>give name inate burg van stad dorp nldspeci nl...</td>\n",
       "      <td>12</td>\n",
       "      <td>national_identity_card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7105</th>\n",
       "      <td>romania identitate romania nume manole tdentit...</td>\n",
       "      <td>28</td>\n",
       "      <td>national_identity_card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7106</th>\n",
       "      <td>issue authority mun bucuresti sec mare idrousp...</td>\n",
       "      <td>8</td>\n",
       "      <td>national_identity_card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7107</th>\n",
       "      <td>roumanie romania didentite identitate identity...</td>\n",
       "      <td>34</td>\n",
       "      <td>national_identity_card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7108</th>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>national_identity_card</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7109 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  words  count  \\\n",
       "0     hazleton laboratory anerca fmc inuoioe ohon mi...     76   \n",
       "1     ragnar rylander invoice consultant fee travel ...     12   \n",
       "2     please remit box chicago invoice invoice date ...    105   \n",
       "3     purchase requisition originator copt sheet rtf...    138   \n",
       "4     hbi healthy building international inc covingt...     69   \n",
       "...                                                 ...    ...   \n",
       "7104  give name inate burg van stad dorp nldspeci nl...     12   \n",
       "7105  romania identitate romania nume manole tdentit...     28   \n",
       "7106  issue authority mun bucuresti sec mare idrousp...      8   \n",
       "7107  roumanie romania didentite identitate identity...     34   \n",
       "7108                                                         0   \n",
       "\n",
       "                    category  \n",
       "0                    invoice  \n",
       "1                    invoice  \n",
       "2                    invoice  \n",
       "3                    invoice  \n",
       "4                    invoice  \n",
       "...                      ...  \n",
       "7104  national_identity_card  \n",
       "7105  national_identity_card  \n",
       "7106  national_identity_card  \n",
       "7107  national_identity_card  \n",
       "7108  national_identity_card  \n",
       "\n",
       "[7109 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = frame_count[frame_count[\"category\"].isin(['passeport', 'national_identity_card', 'email', 'invoice', 'scientific_publication', 'handwritten'])].copy()\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split la data en train et test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "seed = 42\n",
    "data['words'] = data['words'].fillna('')\n",
    "target = data['category']\n",
    "features = data.drop('category', axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, target, test_size=0.2, random_state=seed)\n",
    "\n",
    "df_train = pd.concat((X_train, y_train), axis=1).reset_index(drop=True)\n",
    "df_test = pd.concat((X_test, y_test), axis=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création d'un dictionnaire avec les mots les plus communs pour chaque catégorie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from src import save_jsonfile\n",
    "\n",
    "dic_counter = {}\n",
    "for cat in df_train['category'].unique():\n",
    "    df_cat = df_train[df_train['category'] == cat]\n",
    "    cat_words = ' '.join(df_cat['words'].values)\n",
    "    cat_count = Counter(cat_words.split(' '))\n",
    "    most_common = cat_count.most_common()\n",
    "    most_common = [(word, count) for word, count in most_common if word != \"\"]\n",
    "    dic_counter[cat] = most_common\n",
    "\n",
    "save_jsonfile('data/processed/most_common_words.json', dic_counter, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création de la structure de chaque document, en cherchant la diversité lexicale et la densité des mots-clefs pour chaque catégorie et pour 5, 10, 25 & 50 mots les plus communs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import calculate_lexical_diversity, calculate_keyword_density\n",
    "\n",
    "df_train['lexical_diversity'] = df_train['words'].apply(calculate_lexical_diversity)\n",
    "df_test['lexical_diversity'] = df_test['words'].apply(calculate_lexical_diversity)\n",
    "\n",
    "for cat in df_train['category'].unique():\n",
    "    for k in [5, 10, 25, 50]:\n",
    "        words = [w[0] for w in dic_counter[cat][:k]]\n",
    "        df_train[f\"keyword_{cat}_{k}\"] = df_train['words'].apply(calculate_keyword_density, keywords=words)\n",
    "        df_test[f\"keyword_{cat}_{k}\"] = df_test['words'].apply(calculate_keyword_density, keywords=words)\n",
    "\n",
    "df_train.to_csv(\"data/processed/words_structure_train.csv\", index=False)\n",
    "df_test.to_csv(\"data/processed/words_structure_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>count</th>\n",
       "      <th>category</th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>keyword_passeport_5</th>\n",
       "      <th>keyword_passeport_10</th>\n",
       "      <th>keyword_passeport_25</th>\n",
       "      <th>keyword_passeport_50</th>\n",
       "      <th>keyword_email_5</th>\n",
       "      <th>keyword_email_10</th>\n",
       "      <th>...</th>\n",
       "      <th>keyword_scientific_publication_25</th>\n",
       "      <th>keyword_scientific_publication_50</th>\n",
       "      <th>keyword_handwritten_5</th>\n",
       "      <th>keyword_handwritten_10</th>\n",
       "      <th>keyword_handwritten_25</th>\n",
       "      <th>keyword_handwritten_50</th>\n",
       "      <th>keyword_national_identity_card_5</th>\n",
       "      <th>keyword_national_identity_card_10</th>\n",
       "      <th>keyword_national_identity_card_25</th>\n",
       "      <th>keyword_national_identity_card_50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>latvija latvia gode ste passport berzina anna ...</td>\n",
       "      <td>22</td>\n",
       "      <td>passeport</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.227273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>original karen chaikin pmusa com send tuesday ...</td>\n",
       "      <td>48</td>\n",
       "      <td>email</td>\n",
       "      <td>0.854167</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.104167</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.104167</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.020833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>please return one copy payment covington burl ...</td>\n",
       "      <td>80</td>\n",
       "      <td>invoice</td>\n",
       "      <td>0.862500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.087500</td>\n",
       "      <td>0.037500</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.137500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.012500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>appendix strbasku file copy identification pur...</td>\n",
       "      <td>181</td>\n",
       "      <td>scientific_publication</td>\n",
       "      <td>0.856354</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027624</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060773</td>\n",
       "      <td>0.099448</td>\n",
       "      <td>0.005525</td>\n",
       "      <td>0.005525</td>\n",
       "      <td>0.016575</td>\n",
       "      <td>0.044199</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.027624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>medical school develop commercial liver lily w...</td>\n",
       "      <td>350</td>\n",
       "      <td>scientific_publication</td>\n",
       "      <td>0.848571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008571</td>\n",
       "      <td>0.011429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008571</td>\n",
       "      <td>0.034286</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.048571</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002857</td>\n",
       "      <td>0.008571</td>\n",
       "      <td>0.008571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               words  count  \\\n",
       "0  latvija latvia gode ste passport berzina anna ...     22   \n",
       "1  original karen chaikin pmusa com send tuesday ...     48   \n",
       "2  please return one copy payment covington burl ...     80   \n",
       "3  appendix strbasku file copy identification pur...    181   \n",
       "4  medical school develop commercial liver lily w...    350   \n",
       "\n",
       "                 category  lexical_diversity  keyword_passeport_5  \\\n",
       "0               passeport           0.909091             0.136364   \n",
       "1                   email           0.854167             0.020833   \n",
       "2                 invoice           0.862500             0.012500   \n",
       "3  scientific_publication           0.856354             0.000000   \n",
       "4  scientific_publication           0.848571             0.000000   \n",
       "\n",
       "   keyword_passeport_10  keyword_passeport_25  keyword_passeport_50  \\\n",
       "0              0.136364              0.136364              0.181818   \n",
       "1              0.041667              0.041667              0.041667   \n",
       "2              0.012500              0.050000              0.050000   \n",
       "3              0.000000              0.000000              0.027624   \n",
       "4              0.000000              0.008571              0.011429   \n",
       "\n",
       "   keyword_email_5  keyword_email_10  ...  keyword_scientific_publication_25  \\\n",
       "0         0.000000          0.000000  ...                           0.000000   \n",
       "1         0.041667          0.104167  ...                           0.062500   \n",
       "2         0.050000          0.062500  ...                           0.062500   \n",
       "3         0.000000          0.000000  ...                           0.060773   \n",
       "4         0.000000          0.002857  ...                           0.008571   \n",
       "\n",
       "   keyword_scientific_publication_50  keyword_handwritten_5  \\\n",
       "0                           0.000000               0.000000   \n",
       "1                           0.083333               0.020833   \n",
       "2                           0.087500               0.037500   \n",
       "3                           0.099448               0.005525   \n",
       "4                           0.034286               0.002857   \n",
       "\n",
       "   keyword_handwritten_10  keyword_handwritten_25  keyword_handwritten_50  \\\n",
       "0                0.000000                0.000000                0.000000   \n",
       "1                0.041667                0.062500                0.104167   \n",
       "2                0.062500                0.125000                0.137500   \n",
       "3                0.005525                0.016575                0.044199   \n",
       "4                0.028571                0.048571                0.060000   \n",
       "\n",
       "   keyword_national_identity_card_5  keyword_national_identity_card_10  \\\n",
       "0                          0.090909                           0.136364   \n",
       "1                          0.020833                           0.020833   \n",
       "2                          0.012500                           0.012500   \n",
       "3                          0.000000                           0.000000   \n",
       "4                          0.000000                           0.002857   \n",
       "\n",
       "   keyword_national_identity_card_25  keyword_national_identity_card_50  \n",
       "0                           0.181818                           0.227273  \n",
       "1                           0.020833                           0.020833  \n",
       "2                           0.012500                           0.012500  \n",
       "3                           0.000000                           0.027624  \n",
       "4                           0.008571                           0.008571  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>count</th>\n",
       "      <th>category</th>\n",
       "      <th>lexical_diversity</th>\n",
       "      <th>keyword_passeport_5</th>\n",
       "      <th>keyword_passeport_10</th>\n",
       "      <th>keyword_passeport_25</th>\n",
       "      <th>keyword_passeport_50</th>\n",
       "      <th>keyword_email_5</th>\n",
       "      <th>keyword_email_10</th>\n",
       "      <th>...</th>\n",
       "      <th>keyword_scientific_publication_25</th>\n",
       "      <th>keyword_scientific_publication_50</th>\n",
       "      <th>keyword_handwritten_5</th>\n",
       "      <th>keyword_handwritten_10</th>\n",
       "      <th>keyword_handwritten_25</th>\n",
       "      <th>keyword_handwritten_50</th>\n",
       "      <th>keyword_national_identity_card_5</th>\n",
       "      <th>keyword_national_identity_card_10</th>\n",
       "      <th>keyword_national_identity_card_25</th>\n",
       "      <th>keyword_national_identity_card_50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cal cel page bill date philip morris usa marlb...</td>\n",
       "      <td>60</td>\n",
       "      <td>invoice</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.033333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jackson priscilla gomer bert suggs wae ruffin ...</td>\n",
       "      <td>42</td>\n",
       "      <td>email</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.095238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lietuvi republic lithuania ref bliqu lituanie ...</td>\n",
       "      <td>26</td>\n",
       "      <td>passeport</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>outgoing mal crc contrac business administrati...</td>\n",
       "      <td>96</td>\n",
       "      <td>invoice</td>\n",
       "      <td>0.677083</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010417</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vol acc interstitial preumonitis associate ble...</td>\n",
       "      <td>198</td>\n",
       "      <td>scientific_publication</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005051</td>\n",
       "      <td>0.005051</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065657</td>\n",
       "      <td>0.101010</td>\n",
       "      <td>0.005051</td>\n",
       "      <td>0.005051</td>\n",
       "      <td>0.015152</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               words  count  \\\n",
       "0  cal cel page bill date philip morris usa marlb...     60   \n",
       "1  jackson priscilla gomer bert suggs wae ruffin ...     42   \n",
       "2  lietuvi republic lithuania ref bliqu lituanie ...     26   \n",
       "3  outgoing mal crc contrac business administrati...     96   \n",
       "4  vol acc interstitial preumonitis associate ble...    198   \n",
       "\n",
       "                 category  lexical_diversity  keyword_passeport_5  \\\n",
       "0                 invoice           0.966667             0.016667   \n",
       "1                   email           0.857143             0.095238   \n",
       "2               passeport           0.961538             0.115385   \n",
       "3                 invoice           0.677083             0.000000   \n",
       "4  scientific_publication           0.848485             0.000000   \n",
       "\n",
       "   keyword_passeport_10  keyword_passeport_25  keyword_passeport_50  \\\n",
       "0              0.016667              0.033333              0.066667   \n",
       "1              0.095238              0.095238              0.166667   \n",
       "2              0.115385              0.153846              0.153846   \n",
       "3              0.000000              0.000000              0.010417   \n",
       "4              0.000000              0.005051              0.005051   \n",
       "\n",
       "   keyword_email_5  keyword_email_10  ...  keyword_scientific_publication_25  \\\n",
       "0         0.016667          0.016667  ...                           0.000000   \n",
       "1         0.190476          0.214286  ...                           0.000000   \n",
       "2         0.000000          0.000000  ...                           0.000000   \n",
       "3         0.000000          0.000000  ...                           0.000000   \n",
       "4         0.000000          0.000000  ...                           0.065657   \n",
       "\n",
       "   keyword_scientific_publication_50  keyword_handwritten_5  \\\n",
       "0                           0.016667               0.000000   \n",
       "1                           0.023810               0.023810   \n",
       "2                           0.000000               0.000000   \n",
       "3                           0.000000               0.000000   \n",
       "4                           0.101010               0.005051   \n",
       "\n",
       "   keyword_handwritten_10  keyword_handwritten_25  keyword_handwritten_50  \\\n",
       "0                0.000000                0.016667                0.050000   \n",
       "1                0.023810                0.047619                0.095238   \n",
       "2                0.000000                0.000000                0.000000   \n",
       "3                0.000000                0.000000                0.000000   \n",
       "4                0.005051                0.015152                0.030303   \n",
       "\n",
       "   keyword_national_identity_card_5  keyword_national_identity_card_10  \\\n",
       "0                          0.033333                           0.033333   \n",
       "1                          0.095238                           0.095238   \n",
       "2                          0.000000                           0.000000   \n",
       "3                          0.000000                           0.062500   \n",
       "4                          0.000000                           0.000000   \n",
       "\n",
       "   keyword_national_identity_card_25  keyword_national_identity_card_50  \n",
       "0                           0.033333                           0.033333  \n",
       "1                           0.095238                           0.095238  \n",
       "2                           0.038462                           0.076923  \n",
       "3                           0.062500                           0.062500  \n",
       "4                           0.000000                           0.000000  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
