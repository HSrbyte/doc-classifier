{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "current_dir = %pwd\n",
    "project_dir = os.path.dirname(current_dir)\n",
    "%cd $project_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import save_jsonfile, read_jsonfile, create_train_dataset, create_test_dataset, plot_history\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lire le fichier CSV\n",
    "df_train = pd.read_csv('data/processed/DL_train.csv')\n",
    "df_test = pd.read_csv('data/processed/DL_test.csv')\n",
    "\n",
    "# Convertir les chemins d'images et les Ã©tiquettes en tenseurs\n",
    "X_train = df_train['image_path'].values\n",
    "Y_train = df_train['category'].values\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, Y_train, test_size=0.2, random_state=seed)\n",
    "\n",
    "X_test = df_test['image_path'].values\n",
    "y_test = df_test['category'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = create_train_dataset(X_train, y_train, batch_size)\n",
    "val_dataset = create_train_dataset(X_val, y_val, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " Conv1 (Conv2D)                 (None, 112, 112, 32  864         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " bn_Conv1 (BatchNormalization)  (None, 112, 112, 32  128         ['Conv1[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " Conv1_relu (ReLU)              (None, 112, 112, 32  0           ['bn_Conv1[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise (Depth  (None, 112, 112, 32  288        ['Conv1_relu[0][0]']             \n",
      " wiseConv2D)                    )                                                                 \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_BN (Ba  (None, 112, 112, 32  128        ['expanded_conv_depthwise[0][0]']\n",
      " tchNormalization)              )                                                                 \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_relu (  (None, 112, 112, 32  0          ['expanded_conv_depthwise_BN[0][0\n",
      " ReLU)                          )                                ]']                              \n",
      "                                                                                                  \n",
      " expanded_conv_project (Conv2D)  (None, 112, 112, 16  512        ['expanded_conv_depthwise_relu[0]\n",
      "                                )                                [0]']                            \n",
      "                                                                                                  \n",
      " expanded_conv_project_BN (Batc  (None, 112, 112, 16  64         ['expanded_conv_project[0][0]']  \n",
      " hNormalization)                )                                                                 \n",
      "                                                                                                  \n",
      " block_1_expand (Conv2D)        (None, 112, 112, 96  1536        ['expanded_conv_project_BN[0][0]'\n",
      "                                )                                ]                                \n",
      "                                                                                                  \n",
      " block_1_expand_BN (BatchNormal  (None, 112, 112, 96  384        ['block_1_expand[0][0]']         \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " block_1_expand_relu (ReLU)     (None, 112, 112, 96  0           ['block_1_expand_BN[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_1_pad (ZeroPadding2D)    (None, 113, 113, 96  0           ['block_1_expand_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_1_depthwise (DepthwiseCo  (None, 56, 56, 96)  864         ['block_1_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_1_depthwise_BN (BatchNor  (None, 56, 56, 96)  384         ['block_1_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_1_depthwise_relu (ReLU)  (None, 56, 56, 96)   0           ['block_1_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_1_project (Conv2D)       (None, 56, 56, 24)   2304        ['block_1_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_1_project_BN (BatchNorma  (None, 56, 56, 24)  96          ['block_1_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_expand (Conv2D)        (None, 56, 56, 144)  3456        ['block_1_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_2_expand_BN (BatchNormal  (None, 56, 56, 144)  576        ['block_2_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_2_expand_relu (ReLU)     (None, 56, 56, 144)  0           ['block_2_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_2_depthwise (DepthwiseCo  (None, 56, 56, 144)  1296       ['block_2_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_2_depthwise_BN (BatchNor  (None, 56, 56, 144)  576        ['block_2_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_2_depthwise_relu (ReLU)  (None, 56, 56, 144)  0           ['block_2_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_2_project (Conv2D)       (None, 56, 56, 24)   3456        ['block_2_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_2_project_BN (BatchNorma  (None, 56, 56, 24)  96          ['block_2_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_add (Add)              (None, 56, 56, 24)   0           ['block_1_project_BN[0][0]',     \n",
      "                                                                  'block_2_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_3_expand (Conv2D)        (None, 56, 56, 144)  3456        ['block_2_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_3_expand_BN (BatchNormal  (None, 56, 56, 144)  576        ['block_3_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_3_expand_relu (ReLU)     (None, 56, 56, 144)  0           ['block_3_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_3_pad (ZeroPadding2D)    (None, 57, 57, 144)  0           ['block_3_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_3_depthwise (DepthwiseCo  (None, 28, 28, 144)  1296       ['block_3_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_3_depthwise_BN (BatchNor  (None, 28, 28, 144)  576        ['block_3_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_3_depthwise_relu (ReLU)  (None, 28, 28, 144)  0           ['block_3_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_3_project (Conv2D)       (None, 28, 28, 32)   4608        ['block_3_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_3_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_3_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_3_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_4_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_4_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_4_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_4_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_4_depthwise (DepthwiseCo  (None, 28, 28, 192)  1728       ['block_4_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_4_depthwise_BN (BatchNor  (None, 28, 28, 192)  768        ['block_4_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_4_depthwise_relu (ReLU)  (None, 28, 28, 192)  0           ['block_4_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_4_project (Conv2D)       (None, 28, 28, 32)   6144        ['block_4_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_4_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_4_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_add (Add)              (None, 28, 28, 32)   0           ['block_3_project_BN[0][0]',     \n",
      "                                                                  'block_4_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_5_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_4_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_5_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_5_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_5_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_5_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_5_depthwise (DepthwiseCo  (None, 28, 28, 192)  1728       ['block_5_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_5_depthwise_BN (BatchNor  (None, 28, 28, 192)  768        ['block_5_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_5_depthwise_relu (ReLU)  (None, 28, 28, 192)  0           ['block_5_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_5_project (Conv2D)       (None, 28, 28, 32)   6144        ['block_5_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_5_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_5_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_5_add (Add)              (None, 28, 28, 32)   0           ['block_4_add[0][0]',            \n",
      "                                                                  'block_5_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_6_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_5_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_6_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_6_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_6_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_6_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_6_pad (ZeroPadding2D)    (None, 29, 29, 192)  0           ['block_6_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_6_depthwise (DepthwiseCo  (None, 14, 14, 192)  1728       ['block_6_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_6_depthwise_BN (BatchNor  (None, 14, 14, 192)  768        ['block_6_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_6_depthwise_relu (ReLU)  (None, 14, 14, 192)  0           ['block_6_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_6_project (Conv2D)       (None, 14, 14, 64)   12288       ['block_6_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_6_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_6_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_6_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_7_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_7_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_7_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_7_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_7_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_7_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_7_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_7_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_7_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_7_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_7_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_7_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_7_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_7_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_add (Add)              (None, 14, 14, 64)   0           ['block_6_project_BN[0][0]',     \n",
      "                                                                  'block_7_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_8_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_7_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_8_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_8_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_8_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_8_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_8_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_8_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_8_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_8_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_8_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_8_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_8_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_8_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_8_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_8_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_8_add (Add)              (None, 14, 14, 64)   0           ['block_7_add[0][0]',            \n",
      "                                                                  'block_8_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_9_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_8_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_9_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_9_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_9_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_9_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_9_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_9_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_9_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_9_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_9_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_9_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_9_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_9_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_9_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_9_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_9_add (Add)              (None, 14, 14, 64)   0           ['block_8_add[0][0]',            \n",
      "                                                                  'block_9_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_10_expand (Conv2D)       (None, 14, 14, 384)  24576       ['block_9_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_10_expand_BN (BatchNorma  (None, 14, 14, 384)  1536       ['block_10_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_10_expand_relu (ReLU)    (None, 14, 14, 384)  0           ['block_10_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_10_depthwise (DepthwiseC  (None, 14, 14, 384)  3456       ['block_10_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_10_depthwise_BN (BatchNo  (None, 14, 14, 384)  1536       ['block_10_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_10_depthwise_relu (ReLU)  (None, 14, 14, 384)  0          ['block_10_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_10_project (Conv2D)      (None, 14, 14, 96)   36864       ['block_10_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_10_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_10_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_10_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_11_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_11_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_11_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_11_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_11_depthwise (DepthwiseC  (None, 14, 14, 576)  5184       ['block_11_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_11_depthwise_BN (BatchNo  (None, 14, 14, 576)  2304       ['block_11_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_11_depthwise_relu (ReLU)  (None, 14, 14, 576)  0          ['block_11_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_11_project (Conv2D)      (None, 14, 14, 96)   55296       ['block_11_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_11_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_11_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_add (Add)             (None, 14, 14, 96)   0           ['block_10_project_BN[0][0]',    \n",
      "                                                                  'block_11_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_12_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_11_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_12_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_12_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_12_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_12_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_12_depthwise (DepthwiseC  (None, 14, 14, 576)  5184       ['block_12_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_12_depthwise_BN (BatchNo  (None, 14, 14, 576)  2304       ['block_12_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_12_depthwise_relu (ReLU)  (None, 14, 14, 576)  0          ['block_12_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_12_project (Conv2D)      (None, 14, 14, 96)   55296       ['block_12_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_12_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_12_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_12_add (Add)             (None, 14, 14, 96)   0           ['block_11_add[0][0]',           \n",
      "                                                                  'block_12_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_13_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_12_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_13_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_13_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_13_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_13_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_13_pad (ZeroPadding2D)   (None, 15, 15, 576)  0           ['block_13_expand_relu[0][0]']   \n",
      "                                                                                                  \n",
      " block_13_depthwise (DepthwiseC  (None, 7, 7, 576)   5184        ['block_13_pad[0][0]']           \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_13_depthwise_BN (BatchNo  (None, 7, 7, 576)   2304        ['block_13_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_13_depthwise_relu (ReLU)  (None, 7, 7, 576)   0           ['block_13_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_13_project (Conv2D)      (None, 7, 7, 160)    92160       ['block_13_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_13_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_13_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_13_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_14_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_14_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_14_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_14_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_14_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_14_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_14_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_14_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_14_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_14_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_14_project (Conv2D)      (None, 7, 7, 160)    153600      ['block_14_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_14_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_14_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_add (Add)             (None, 7, 7, 160)    0           ['block_13_project_BN[0][0]',    \n",
      "                                                                  'block_14_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_15_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_14_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_15_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_15_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_15_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_15_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_15_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_15_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_15_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_15_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_15_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_15_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_15_project (Conv2D)      (None, 7, 7, 160)    153600      ['block_15_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_15_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_15_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_15_add (Add)             (None, 7, 7, 160)    0           ['block_14_add[0][0]',           \n",
      "                                                                  'block_15_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_16_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_15_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_16_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_16_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_16_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_16_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_16_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_16_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_16_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_16_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_16_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_16_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_16_project (Conv2D)      (None, 7, 7, 320)    307200      ['block_16_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_16_project_BN (BatchNorm  (None, 7, 7, 320)   1280        ['block_16_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " Conv_1 (Conv2D)                (None, 7, 7, 1280)   409600      ['block_16_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " Conv_1_bn (BatchNormalization)  (None, 7, 7, 1280)  5120        ['Conv_1[0][0]']                 \n",
      "                                                                                                  \n",
      " out_relu (ReLU)                (None, 7, 7, 1280)   0           ['Conv_1_bn[0][0]']              \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 1280)        0           ['out_relu[0][0]']               \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1024)         1311744     ['global_average_pooling2d[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 6)            6150        ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 3,575,878\n",
      "Trainable params: 3,541,766\n",
      "Non-trainable params: 34,112\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model = tf.keras.applications.MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights='imagenet') # Charger MobileNetV2 sans la couche de tÃªte\n",
    "x = base_model.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x) # Ajouter une couche de pooling global\n",
    "x = tf.keras.layers.Dense(1024, activation='relu')(x) # Ajouter une nouvelle couche dense\n",
    "predictions = tf.keras.layers.Dense(6, activation='softmax')(x) # La nouvelle couche de sortie pour 6 classes\n",
    "model = tf.keras.Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# CrÃ©er l'optimiseur avec le taux d'apprentissage souhaitÃ©\n",
    "learning_rate = 0.0001\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "\n",
    "# Compiler le modÃ¨le\n",
    "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_best_acc = ModelCheckpoint(\n",
    "    filepath='models/MobileNetV2_ckpt_best_acc.keras',\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "ckpt_best_loss = ModelCheckpoint(\n",
    "    filepath='models/MobileNetV2_ckpt_best_loss.keras',\n",
    "    monitor='val_loss',\n",
    "    save_best_only=True,\n",
    "    mode='min',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=10,\n",
    "    min_lr=1e-9,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-28 11:12:27.218811: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8800\n",
      "2024-06-28 11:12:31.085932: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "171/171 [==============================] - ETA: 0s - loss: 0.3479 - accuracy: 0.8837\n",
      "Epoch 1: val_accuracy improved from -inf to 0.47141, saving model to models/MobileNetV2_ckpt_best_acc.keras\n",
      "\n",
      "Epoch 1: val_loss improved from inf to 1.60868, saving model to models/MobileNetV2_ckpt_best_loss.keras\n",
      "171/171 [==============================] - 127s 660ms/step - loss: 0.3479 - accuracy: 0.8837 - val_loss: 1.6087 - val_accuracy: 0.4714 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 0.1393 - accuracy: 0.9529\n",
      "Epoch 2: val_accuracy improved from 0.47141 to 0.47507, saving model to models/MobileNetV2_ckpt_best_acc.keras\n",
      "\n",
      "Epoch 2: val_loss did not improve from 1.60868\n",
      "171/171 [==============================] - 111s 647ms/step - loss: 0.1393 - accuracy: 0.9529 - val_loss: 1.9536 - val_accuracy: 0.4751 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 0.0901 - accuracy: 0.9719\n",
      "Epoch 3: val_accuracy improved from 0.47507 to 0.69428, saving model to models/MobileNetV2_ckpt_best_acc.keras\n",
      "\n",
      "Epoch 3: val_loss improved from 1.60868 to 0.91876, saving model to models/MobileNetV2_ckpt_best_loss.keras\n",
      "171/171 [==============================] - 109s 636ms/step - loss: 0.0901 - accuracy: 0.9719 - val_loss: 0.9188 - val_accuracy: 0.6943 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 0.0713 - accuracy: 0.9769\n",
      "Epoch 4: val_accuracy did not improve from 0.69428\n",
      "\n",
      "Epoch 4: val_loss did not improve from 0.91876\n",
      "171/171 [==============================] - 108s 632ms/step - loss: 0.0713 - accuracy: 0.9769 - val_loss: 1.4383 - val_accuracy: 0.6408 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 0.0411 - accuracy: 0.9853\n",
      "Epoch 5: val_accuracy improved from 0.69428 to 0.78739, saving model to models/MobileNetV2_ckpt_best_acc.keras\n",
      "\n",
      "Epoch 5: val_loss improved from 0.91876 to 0.74325, saving model to models/MobileNetV2_ckpt_best_loss.keras\n",
      "171/171 [==============================] - 110s 639ms/step - loss: 0.0411 - accuracy: 0.9853 - val_loss: 0.7432 - val_accuracy: 0.7874 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 0.0308 - accuracy: 0.9906\n",
      "Epoch 6: val_accuracy improved from 0.78739 to 0.82845, saving model to models/MobileNetV2_ckpt_best_acc.keras\n",
      "\n",
      "Epoch 6: val_loss improved from 0.74325 to 0.59871, saving model to models/MobileNetV2_ckpt_best_loss.keras\n",
      "171/171 [==============================] - 109s 638ms/step - loss: 0.0308 - accuracy: 0.9906 - val_loss: 0.5987 - val_accuracy: 0.8284 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 0.0304 - accuracy: 0.9890\n",
      "Epoch 7: val_accuracy improved from 0.82845 to 0.87977, saving model to models/MobileNetV2_ckpt_best_acc.keras\n",
      "\n",
      "Epoch 7: val_loss improved from 0.59871 to 0.45718, saving model to models/MobileNetV2_ckpt_best_loss.keras\n",
      "171/171 [==============================] - 110s 643ms/step - loss: 0.0304 - accuracy: 0.9890 - val_loss: 0.4572 - val_accuracy: 0.8798 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 0.0232 - accuracy: 0.9917\n",
      "Epoch 8: val_accuracy improved from 0.87977 to 0.88563, saving model to models/MobileNetV2_ckpt_best_acc.keras\n",
      "\n",
      "Epoch 8: val_loss did not improve from 0.45718\n",
      "171/171 [==============================] - 109s 635ms/step - loss: 0.0232 - accuracy: 0.9917 - val_loss: 0.5122 - val_accuracy: 0.8856 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 0.0228 - accuracy: 0.9932\n",
      "Epoch 9: val_accuracy improved from 0.88563 to 0.92009, saving model to models/MobileNetV2_ckpt_best_acc.keras\n",
      "\n",
      "Epoch 9: val_loss improved from 0.45718 to 0.35766, saving model to models/MobileNetV2_ckpt_best_loss.keras\n",
      "171/171 [==============================] - 110s 640ms/step - loss: 0.0228 - accuracy: 0.9932 - val_loss: 0.3577 - val_accuracy: 0.9201 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 0.0312 - accuracy: 0.9905\n",
      "Epoch 10: val_accuracy improved from 0.92009 to 0.94062, saving model to models/MobileNetV2_ckpt_best_acc.keras\n",
      "\n",
      "Epoch 10: val_loss improved from 0.35766 to 0.20925, saving model to models/MobileNetV2_ckpt_best_loss.keras\n",
      "171/171 [==============================] - 110s 642ms/step - loss: 0.0312 - accuracy: 0.9905 - val_loss: 0.2093 - val_accuracy: 0.9406 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 0.0179 - accuracy: 0.9939\n",
      "Epoch 11: val_accuracy improved from 0.94062 to 0.95968, saving model to models/MobileNetV2_ckpt_best_acc.keras\n",
      "\n",
      "Epoch 11: val_loss improved from 0.20925 to 0.16243, saving model to models/MobileNetV2_ckpt_best_loss.keras\n",
      "171/171 [==============================] - 109s 636ms/step - loss: 0.0179 - accuracy: 0.9939 - val_loss: 0.1624 - val_accuracy: 0.9597 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 0.0288 - accuracy: 0.9903\n",
      "Epoch 12: val_accuracy did not improve from 0.95968\n",
      "\n",
      "Epoch 12: val_loss did not improve from 0.16243\n",
      "171/171 [==============================] - 108s 634ms/step - loss: 0.0288 - accuracy: 0.9903 - val_loss: 0.2650 - val_accuracy: 0.9472 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 0.0245 - accuracy: 0.9917\n",
      "Epoch 13: val_accuracy did not improve from 0.95968\n",
      "\n",
      "Epoch 13: val_loss did not improve from 0.16243\n",
      "171/171 [==============================] - 109s 636ms/step - loss: 0.0245 - accuracy: 0.9917 - val_loss: 0.2291 - val_accuracy: 0.9545 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 0.0289 - accuracy: 0.9897\n",
      "Epoch 14: val_accuracy did not improve from 0.95968\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.16243\n",
      "171/171 [==============================] - 110s 640ms/step - loss: 0.0289 - accuracy: 0.9897 - val_loss: 0.2678 - val_accuracy: 0.9531 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 0.0137 - accuracy: 0.9961\n",
      "Epoch 15: val_accuracy improved from 0.95968 to 0.97434, saving model to models/MobileNetV2_ckpt_best_acc.keras\n",
      "\n",
      "Epoch 15: val_loss improved from 0.16243 to 0.10690, saving model to models/MobileNetV2_ckpt_best_loss.keras\n",
      "171/171 [==============================] - 110s 640ms/step - loss: 0.0137 - accuracy: 0.9961 - val_loss: 0.1069 - val_accuracy: 0.9743 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 0.9982\n",
      "Epoch 16: val_accuracy did not improve from 0.97434\n",
      "\n",
      "Epoch 16: val_loss did not improve from 0.10690\n",
      "171/171 [==============================] - 109s 636ms/step - loss: 0.0060 - accuracy: 0.9982 - val_loss: 0.1569 - val_accuracy: 0.9699 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 0.0076 - accuracy: 0.9982\n",
      "Epoch 17: val_accuracy did not improve from 0.97434\n",
      "\n",
      "Epoch 17: val_loss did not improve from 0.10690\n",
      "171/171 [==============================] - 110s 643ms/step - loss: 0.0076 - accuracy: 0.9982 - val_loss: 0.1593 - val_accuracy: 0.9692 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 0.0210 - accuracy: 0.9925\n",
      "Epoch 18: val_accuracy did not improve from 0.97434\n",
      "\n",
      "Epoch 18: val_loss did not improve from 0.10690\n",
      "171/171 [==============================] - 111s 647ms/step - loss: 0.0210 - accuracy: 0.9925 - val_loss: 0.1494 - val_accuracy: 0.9641 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 0.0282 - accuracy: 0.9921\n",
      "Epoch 19: val_accuracy did not improve from 0.97434\n",
      "\n",
      "Epoch 19: val_loss did not improve from 0.10690\n",
      "171/171 [==============================] - 110s 641ms/step - loss: 0.0282 - accuracy: 0.9921 - val_loss: 0.1501 - val_accuracy: 0.9655 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 0.0178 - accuracy: 0.9954\n",
      "Epoch 20: val_accuracy did not improve from 0.97434\n",
      "\n",
      "Epoch 20: val_loss did not improve from 0.10690\n",
      "171/171 [==============================] - 112s 652ms/step - loss: 0.0178 - accuracy: 0.9954 - val_loss: 0.1094 - val_accuracy: 0.9721 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 0.0167 - accuracy: 0.9943\n",
      "Epoch 21: val_accuracy did not improve from 0.97434\n",
      "\n",
      "Epoch 21: val_loss did not improve from 0.10690\n",
      "171/171 [==============================] - 112s 652ms/step - loss: 0.0167 - accuracy: 0.9943 - val_loss: 0.1669 - val_accuracy: 0.9685 - lr: 1.0000e-04\n",
      "Epoch 22/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 0.0097 - accuracy: 0.9965\n",
      "Epoch 22: val_accuracy did not improve from 0.97434\n",
      "\n",
      "Epoch 22: val_loss did not improve from 0.10690\n",
      "171/171 [==============================] - 111s 648ms/step - loss: 0.0097 - accuracy: 0.9965 - val_loss: 0.1424 - val_accuracy: 0.9685 - lr: 1.0000e-04\n",
      "Epoch 23/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 0.0149 - accuracy: 0.9950\n",
      "Epoch 23: val_accuracy did not improve from 0.97434\n",
      "\n",
      "Epoch 23: val_loss did not improve from 0.10690\n",
      "171/171 [==============================] - 112s 654ms/step - loss: 0.0149 - accuracy: 0.9950 - val_loss: 0.1123 - val_accuracy: 0.9736 - lr: 1.0000e-04\n",
      "Epoch 24/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 0.0082 - accuracy: 0.9972\n",
      "Epoch 24: val_accuracy did not improve from 0.97434\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.10690\n",
      "171/171 [==============================] - 112s 655ms/step - loss: 0.0082 - accuracy: 0.9972 - val_loss: 0.1228 - val_accuracy: 0.9743 - lr: 1.0000e-04\n",
      "Epoch 25/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 0.0048 - accuracy: 0.9985\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 1.9999999494757503e-05.\n",
      "\n",
      "Epoch 25: val_accuracy improved from 0.97434 to 0.97727, saving model to models/MobileNetV2_ckpt_best_acc.keras\n",
      "\n",
      "Epoch 25: val_loss did not improve from 0.10690\n",
      "171/171 [==============================] - 113s 663ms/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.1186 - val_accuracy: 0.9773 - lr: 1.0000e-04\n",
      "Epoch 26/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 0.0025 - accuracy: 0.9991\n",
      "Epoch 26: val_accuracy did not improve from 0.97727\n",
      "\n",
      "Epoch 26: val_loss did not improve from 0.10690\n",
      "171/171 [==============================] - 119s 694ms/step - loss: 0.0025 - accuracy: 0.9991 - val_loss: 0.1215 - val_accuracy: 0.9736 - lr: 2.0000e-05\n",
      "Epoch 27/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 9.0828e-04 - accuracy: 0.9998\n",
      "Epoch 27: val_accuracy improved from 0.97727 to 0.98021, saving model to models/MobileNetV2_ckpt_best_acc.keras\n",
      "\n",
      "Epoch 27: val_loss improved from 0.10690 to 0.09096, saving model to models/MobileNetV2_ckpt_best_loss.keras\n",
      "171/171 [==============================] - 118s 689ms/step - loss: 9.0828e-04 - accuracy: 0.9998 - val_loss: 0.0910 - val_accuracy: 0.9802 - lr: 2.0000e-05\n",
      "Epoch 28/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 7.4105e-04 - accuracy: 1.0000\n",
      "Epoch 28: val_accuracy did not improve from 0.98021\n",
      "\n",
      "Epoch 28: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 117s 683ms/step - loss: 7.4105e-04 - accuracy: 1.0000 - val_loss: 0.1222 - val_accuracy: 0.9751 - lr: 2.0000e-05\n",
      "Epoch 29/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 0.0019 - accuracy: 0.9994\n",
      "Epoch 29: val_accuracy did not improve from 0.98021\n",
      "\n",
      "Epoch 29: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 119s 696ms/step - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.1088 - val_accuracy: 0.9787 - lr: 2.0000e-05\n",
      "Epoch 30/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 9.1774e-04 - accuracy: 0.9998\n",
      "Epoch 30: val_accuracy did not improve from 0.98021\n",
      "\n",
      "Epoch 30: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 117s 686ms/step - loss: 9.1774e-04 - accuracy: 0.9998 - val_loss: 0.1194 - val_accuracy: 0.9780 - lr: 2.0000e-05\n",
      "Epoch 31/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 6.5399e-04 - accuracy: 1.0000\n",
      "Epoch 31: val_accuracy did not improve from 0.98021\n",
      "\n",
      "Epoch 31: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 116s 677ms/step - loss: 6.5399e-04 - accuracy: 1.0000 - val_loss: 0.1271 - val_accuracy: 0.9736 - lr: 2.0000e-05\n",
      "Epoch 32/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 3.0365e-04 - accuracy: 1.0000\n",
      "Epoch 32: val_accuracy did not improve from 0.98021\n",
      "\n",
      "Epoch 32: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 117s 685ms/step - loss: 3.0365e-04 - accuracy: 1.0000 - val_loss: 0.1094 - val_accuracy: 0.9773 - lr: 2.0000e-05\n",
      "Epoch 33/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 2.8149e-04 - accuracy: 1.0000\n",
      "Epoch 33: val_accuracy did not improve from 0.98021\n",
      "\n",
      "Epoch 33: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 116s 678ms/step - loss: 2.8149e-04 - accuracy: 1.0000 - val_loss: 0.1124 - val_accuracy: 0.9773 - lr: 2.0000e-05\n",
      "Epoch 34/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 2.6171e-04 - accuracy: 1.0000\n",
      "Epoch 34: val_accuracy did not improve from 0.98021\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 114s 666ms/step - loss: 2.6171e-04 - accuracy: 1.0000 - val_loss: 0.1279 - val_accuracy: 0.9736 - lr: 2.0000e-05\n",
      "Epoch 35/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 0.0013 - accuracy: 0.9996\n",
      "Epoch 35: val_accuracy did not improve from 0.98021\n",
      "\n",
      "Epoch 35: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 114s 666ms/step - loss: 0.0013 - accuracy: 0.9996 - val_loss: 0.1253 - val_accuracy: 0.9765 - lr: 2.0000e-05\n",
      "Epoch 36/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 2.6451e-04 - accuracy: 1.0000\n",
      "Epoch 36: val_accuracy did not improve from 0.98021\n",
      "\n",
      "Epoch 36: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 115s 673ms/step - loss: 2.6451e-04 - accuracy: 1.0000 - val_loss: 0.1223 - val_accuracy: 0.9751 - lr: 2.0000e-05\n",
      "Epoch 37/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 2.9212e-04 - accuracy: 1.0000\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 3.999999898951501e-06.\n",
      "\n",
      "Epoch 37: val_accuracy did not improve from 0.98021\n",
      "\n",
      "Epoch 37: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 131s 764ms/step - loss: 2.9212e-04 - accuracy: 1.0000 - val_loss: 0.1384 - val_accuracy: 0.9729 - lr: 2.0000e-05\n",
      "Epoch 38/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 3.3300e-04 - accuracy: 0.9998\n",
      "Epoch 38: val_accuracy did not improve from 0.98021\n",
      "\n",
      "Epoch 38: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 115s 673ms/step - loss: 3.3300e-04 - accuracy: 0.9998 - val_loss: 0.1159 - val_accuracy: 0.9743 - lr: 4.0000e-06\n",
      "Epoch 39/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 2.0842e-04 - accuracy: 1.0000\n",
      "Epoch 39: val_accuracy did not improve from 0.98021\n",
      "\n",
      "Epoch 39: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 115s 671ms/step - loss: 2.0842e-04 - accuracy: 1.0000 - val_loss: 0.1278 - val_accuracy: 0.9751 - lr: 4.0000e-06\n",
      "Epoch 40/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 2.5221e-04 - accuracy: 1.0000\n",
      "Epoch 40: val_accuracy did not improve from 0.98021\n",
      "\n",
      "Epoch 40: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 116s 674ms/step - loss: 2.5221e-04 - accuracy: 1.0000 - val_loss: 0.0965 - val_accuracy: 0.9758 - lr: 4.0000e-06\n",
      "Epoch 41/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 1.5049e-04 - accuracy: 1.0000\n",
      "Epoch 41: val_accuracy did not improve from 0.98021\n",
      "\n",
      "Epoch 41: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 117s 682ms/step - loss: 1.5049e-04 - accuracy: 1.0000 - val_loss: 0.1195 - val_accuracy: 0.9758 - lr: 4.0000e-06\n",
      "Epoch 42/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 2.4341e-04 - accuracy: 1.0000\n",
      "Epoch 42: val_accuracy did not improve from 0.98021\n",
      "\n",
      "Epoch 42: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 116s 680ms/step - loss: 2.4341e-04 - accuracy: 1.0000 - val_loss: 0.1212 - val_accuracy: 0.9751 - lr: 4.0000e-06\n",
      "Epoch 43/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 1.6118e-04 - accuracy: 1.0000\n",
      "Epoch 43: val_accuracy did not improve from 0.98021\n",
      "\n",
      "Epoch 43: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 118s 687ms/step - loss: 1.6118e-04 - accuracy: 1.0000 - val_loss: 0.1142 - val_accuracy: 0.9765 - lr: 4.0000e-06\n",
      "Epoch 44/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 1.1573e-04 - accuracy: 1.0000\n",
      "Epoch 44: val_accuracy did not improve from 0.98021\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 118s 691ms/step - loss: 1.1573e-04 - accuracy: 1.0000 - val_loss: 0.1121 - val_accuracy: 0.9787 - lr: 4.0000e-06\n",
      "Epoch 45/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 1.3446e-04 - accuracy: 1.0000\n",
      "Epoch 45: val_accuracy did not improve from 0.98021\n",
      "\n",
      "Epoch 45: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 118s 691ms/step - loss: 1.3446e-04 - accuracy: 1.0000 - val_loss: 0.1360 - val_accuracy: 0.9736 - lr: 4.0000e-06\n",
      "Epoch 46/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 1.2853e-04 - accuracy: 1.0000\n",
      "Epoch 46: val_accuracy did not improve from 0.98021\n",
      "\n",
      "Epoch 46: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 118s 688ms/step - loss: 1.2853e-04 - accuracy: 1.0000 - val_loss: 0.1267 - val_accuracy: 0.9743 - lr: 4.0000e-06\n",
      "Epoch 47/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 4.2045e-04 - accuracy: 0.9998\n",
      "Epoch 47: ReduceLROnPlateau reducing learning rate to 7.999999979801942e-07.\n",
      "\n",
      "Epoch 47: val_accuracy did not improve from 0.98021\n",
      "\n",
      "Epoch 47: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 121s 704ms/step - loss: 4.2045e-04 - accuracy: 0.9998 - val_loss: 0.0934 - val_accuracy: 0.9795 - lr: 4.0000e-06\n",
      "Epoch 48/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 3.3045e-04 - accuracy: 0.9998\n",
      "Epoch 48: val_accuracy did not improve from 0.98021\n",
      "\n",
      "Epoch 48: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 121s 708ms/step - loss: 3.3045e-04 - accuracy: 0.9998 - val_loss: 0.1206 - val_accuracy: 0.9765 - lr: 8.0000e-07\n",
      "Epoch 49/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 1.8710e-04 - accuracy: 1.0000\n",
      "Epoch 49: val_accuracy did not improve from 0.98021\n",
      "\n",
      "Epoch 49: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 120s 703ms/step - loss: 1.8710e-04 - accuracy: 1.0000 - val_loss: 0.1003 - val_accuracy: 0.9795 - lr: 8.0000e-07\n",
      "Epoch 50/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 3.0426e-04 - accuracy: 1.0000\n",
      "Epoch 50: val_accuracy did not improve from 0.98021\n",
      "\n",
      "Epoch 50: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 122s 713ms/step - loss: 3.0426e-04 - accuracy: 1.0000 - val_loss: 0.0968 - val_accuracy: 0.9743 - lr: 8.0000e-07\n",
      "Epoch 51/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 5.3688e-04 - accuracy: 0.9998\n",
      "Epoch 51: val_accuracy improved from 0.98021 to 0.98094, saving model to models/MobileNetV2_ckpt_best_acc.keras\n",
      "\n",
      "Epoch 51: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 124s 723ms/step - loss: 5.3688e-04 - accuracy: 0.9998 - val_loss: 0.0950 - val_accuracy: 0.9809 - lr: 8.0000e-07\n",
      "Epoch 52/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 2.8771e-04 - accuracy: 0.9998\n",
      "Epoch 52: val_accuracy did not improve from 0.98094\n",
      "\n",
      "Epoch 52: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 123s 719ms/step - loss: 2.8771e-04 - accuracy: 0.9998 - val_loss: 0.1214 - val_accuracy: 0.9751 - lr: 8.0000e-07\n",
      "Epoch 53/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 1.6971e-04 - accuracy: 1.0000\n",
      "Epoch 53: val_accuracy did not improve from 0.98094\n",
      "\n",
      "Epoch 53: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 130s 756ms/step - loss: 1.6971e-04 - accuracy: 1.0000 - val_loss: 0.0959 - val_accuracy: 0.9773 - lr: 8.0000e-07\n",
      "Epoch 54/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 1.6957e-04 - accuracy: 1.0000\n",
      "Epoch 54: val_accuracy did not improve from 0.98094\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 134s 783ms/step - loss: 1.6957e-04 - accuracy: 1.0000 - val_loss: 0.1133 - val_accuracy: 0.9773 - lr: 8.0000e-07\n",
      "Epoch 55/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 1.9074e-04 - accuracy: 1.0000\n",
      "Epoch 55: val_accuracy did not improve from 0.98094\n",
      "\n",
      "Epoch 55: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 125s 732ms/step - loss: 1.9074e-04 - accuracy: 1.0000 - val_loss: 0.1024 - val_accuracy: 0.9780 - lr: 8.0000e-07\n",
      "Epoch 56/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 1.1523e-04 - accuracy: 1.0000\n",
      "Epoch 56: val_accuracy did not improve from 0.98094\n",
      "\n",
      "Epoch 56: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 117s 686ms/step - loss: 1.1523e-04 - accuracy: 1.0000 - val_loss: 0.1183 - val_accuracy: 0.9751 - lr: 8.0000e-07\n",
      "Epoch 57/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 2.2338e-04 - accuracy: 1.0000\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 1.600000018697756e-07.\n",
      "\n",
      "Epoch 57: val_accuracy did not improve from 0.98094\n",
      "\n",
      "Epoch 57: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 116s 674ms/step - loss: 2.2338e-04 - accuracy: 1.0000 - val_loss: 0.1177 - val_accuracy: 0.9758 - lr: 8.0000e-07\n",
      "Epoch 58/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 1.9643e-04 - accuracy: 1.0000\n",
      "Epoch 58: val_accuracy did not improve from 0.98094\n",
      "\n",
      "Epoch 58: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 119s 694ms/step - loss: 1.9643e-04 - accuracy: 1.0000 - val_loss: 0.1059 - val_accuracy: 0.9743 - lr: 1.6000e-07\n",
      "Epoch 59/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 9.6235e-05 - accuracy: 1.0000\n",
      "Epoch 59: val_accuracy did not improve from 0.98094\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 116s 676ms/step - loss: 9.6235e-05 - accuracy: 1.0000 - val_loss: 0.1005 - val_accuracy: 0.9729 - lr: 1.6000e-07\n",
      "Epoch 60/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 1.2871e-04 - accuracy: 1.0000\n",
      "Epoch 60: val_accuracy did not improve from 0.98094\n",
      "\n",
      "Epoch 60: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 116s 676ms/step - loss: 1.2871e-04 - accuracy: 1.0000 - val_loss: 0.1201 - val_accuracy: 0.9736 - lr: 1.6000e-07\n",
      "Epoch 61/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 1.6100e-04 - accuracy: 1.0000\n",
      "Epoch 61: val_accuracy did not improve from 0.98094\n",
      "\n",
      "Epoch 61: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 115s 674ms/step - loss: 1.6100e-04 - accuracy: 1.0000 - val_loss: 0.1112 - val_accuracy: 0.9773 - lr: 1.6000e-07\n",
      "Epoch 62/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 1.4008e-04 - accuracy: 1.0000\n",
      "Epoch 62: val_accuracy did not improve from 0.98094\n",
      "\n",
      "Epoch 62: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 115s 670ms/step - loss: 1.4008e-04 - accuracy: 1.0000 - val_loss: 0.1115 - val_accuracy: 0.9787 - lr: 1.6000e-07\n",
      "Epoch 63/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 2.1531e-04 - accuracy: 1.0000\n",
      "Epoch 63: val_accuracy did not improve from 0.98094\n",
      "\n",
      "Epoch 63: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 115s 675ms/step - loss: 2.1531e-04 - accuracy: 1.0000 - val_loss: 0.1076 - val_accuracy: 0.9743 - lr: 1.6000e-07\n",
      "Epoch 64/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 3.4429e-04 - accuracy: 0.9998\n",
      "Epoch 64: val_accuracy did not improve from 0.98094\n",
      "\n",
      "Epoch 64: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 115s 673ms/step - loss: 3.4429e-04 - accuracy: 0.9998 - val_loss: 0.1019 - val_accuracy: 0.9765 - lr: 1.6000e-07\n",
      "Epoch 65/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 1.4501e-04 - accuracy: 1.0000\n",
      "Epoch 65: val_accuracy did not improve from 0.98094\n",
      "\n",
      "Epoch 65: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 115s 670ms/step - loss: 1.4501e-04 - accuracy: 1.0000 - val_loss: 0.1205 - val_accuracy: 0.9736 - lr: 1.6000e-07\n",
      "Epoch 66/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 1.7246e-04 - accuracy: 1.0000\n",
      "Epoch 66: val_accuracy did not improve from 0.98094\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 114s 669ms/step - loss: 1.7246e-04 - accuracy: 1.0000 - val_loss: 0.1326 - val_accuracy: 0.9736 - lr: 1.6000e-07\n",
      "Epoch 67/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 1.7177e-04 - accuracy: 1.0000\n",
      "Epoch 67: ReduceLROnPlateau reducing learning rate to 3.199999980552093e-08.\n",
      "\n",
      "Epoch 67: val_accuracy did not improve from 0.98094\n",
      "\n",
      "Epoch 67: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 115s 673ms/step - loss: 1.7177e-04 - accuracy: 1.0000 - val_loss: 0.1105 - val_accuracy: 0.9751 - lr: 1.6000e-07\n",
      "Epoch 68/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 8.4913e-05 - accuracy: 1.0000\n",
      "Epoch 68: val_accuracy did not improve from 0.98094\n",
      "\n",
      "Epoch 68: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 115s 671ms/step - loss: 8.4913e-05 - accuracy: 1.0000 - val_loss: 0.1052 - val_accuracy: 0.9787 - lr: 3.2000e-08\n",
      "Epoch 69/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 2.2888e-04 - accuracy: 1.0000\n",
      "Epoch 69: val_accuracy did not improve from 0.98094\n",
      "\n",
      "Epoch 69: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 115s 674ms/step - loss: 2.2888e-04 - accuracy: 1.0000 - val_loss: 0.1355 - val_accuracy: 0.9758 - lr: 3.2000e-08\n",
      "Epoch 70/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 1.1081e-04 - accuracy: 1.0000\n",
      "Epoch 70: val_accuracy did not improve from 0.98094\n",
      "\n",
      "Epoch 70: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 116s 677ms/step - loss: 1.1081e-04 - accuracy: 1.0000 - val_loss: 0.1039 - val_accuracy: 0.9780 - lr: 3.2000e-08\n",
      "Epoch 71/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 1.5979e-04 - accuracy: 1.0000\n",
      "Epoch 71: val_accuracy did not improve from 0.98094\n",
      "\n",
      "Epoch 71: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 115s 676ms/step - loss: 1.5979e-04 - accuracy: 1.0000 - val_loss: 0.1007 - val_accuracy: 0.9787 - lr: 3.2000e-08\n",
      "Epoch 72/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 1.7643e-04 - accuracy: 1.0000\n",
      "Epoch 72: val_accuracy did not improve from 0.98094\n",
      "\n",
      "Epoch 72: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 116s 676ms/step - loss: 1.7643e-04 - accuracy: 1.0000 - val_loss: 0.1095 - val_accuracy: 0.9765 - lr: 3.2000e-08\n",
      "Epoch 73/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 2.1680e-04 - accuracy: 1.0000\n",
      "Epoch 73: val_accuracy did not improve from 0.98094\n",
      "\n",
      "Epoch 73: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 115s 674ms/step - loss: 2.1680e-04 - accuracy: 1.0000 - val_loss: 0.1104 - val_accuracy: 0.9743 - lr: 3.2000e-08\n",
      "Epoch 74/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 9.8609e-05 - accuracy: 1.0000\n",
      "Epoch 74: val_accuracy did not improve from 0.98094\n",
      "\n",
      "Epoch 74: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 116s 678ms/step - loss: 9.8609e-05 - accuracy: 1.0000 - val_loss: 0.1194 - val_accuracy: 0.9787 - lr: 3.2000e-08\n",
      "Epoch 75/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 1.6500e-04 - accuracy: 1.0000\n",
      "Epoch 75: val_accuracy did not improve from 0.98094\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 116s 679ms/step - loss: 1.6500e-04 - accuracy: 1.0000 - val_loss: 0.1091 - val_accuracy: 0.9765 - lr: 3.2000e-08\n",
      "Epoch 76/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 1.2140e-04 - accuracy: 1.0000\n",
      "Epoch 76: val_accuracy did not improve from 0.98094\n",
      "\n",
      "Epoch 76: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 116s 676ms/step - loss: 1.2140e-04 - accuracy: 1.0000 - val_loss: 0.1204 - val_accuracy: 0.9773 - lr: 3.2000e-08\n",
      "Epoch 77/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 1.2169e-04 - accuracy: 1.0000\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 6.399999818995639e-09.\n",
      "\n",
      "Epoch 77: val_accuracy did not improve from 0.98094\n",
      "\n",
      "Epoch 77: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 115s 674ms/step - loss: 1.2169e-04 - accuracy: 1.0000 - val_loss: 0.1316 - val_accuracy: 0.9751 - lr: 3.2000e-08\n",
      "Epoch 78/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 1.5400e-04 - accuracy: 1.0000\n",
      "Epoch 78: val_accuracy did not improve from 0.98094\n",
      "\n",
      "Epoch 78: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 116s 676ms/step - loss: 1.5400e-04 - accuracy: 1.0000 - val_loss: 0.1052 - val_accuracy: 0.9780 - lr: 6.4000e-09\n",
      "Epoch 79/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 1.0127e-04 - accuracy: 1.0000\n",
      "Epoch 79: val_accuracy did not improve from 0.98094\n",
      "\n",
      "Epoch 79: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 116s 676ms/step - loss: 1.0127e-04 - accuracy: 1.0000 - val_loss: 0.1075 - val_accuracy: 0.9780 - lr: 6.4000e-09\n",
      "Epoch 80/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 1.5997e-04 - accuracy: 1.0000\n",
      "Epoch 80: val_accuracy did not improve from 0.98094\n",
      "\n",
      "Epoch 80: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 115s 672ms/step - loss: 1.5997e-04 - accuracy: 1.0000 - val_loss: 0.1134 - val_accuracy: 0.9743 - lr: 6.4000e-09\n",
      "Epoch 81/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 1.1073e-04 - accuracy: 1.0000\n",
      "Epoch 81: val_accuracy did not improve from 0.98094\n",
      "\n",
      "Epoch 81: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 116s 678ms/step - loss: 1.1073e-04 - accuracy: 1.0000 - val_loss: 0.1056 - val_accuracy: 0.9758 - lr: 6.4000e-09\n",
      "Epoch 82/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 1.0362e-04 - accuracy: 1.0000\n",
      "Epoch 82: val_accuracy did not improve from 0.98094\n",
      "\n",
      "Epoch 82: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 116s 677ms/step - loss: 1.0362e-04 - accuracy: 1.0000 - val_loss: 0.1155 - val_accuracy: 0.9743 - lr: 6.4000e-09\n",
      "Epoch 83/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 9.9825e-05 - accuracy: 1.0000\n",
      "Epoch 83: val_accuracy did not improve from 0.98094\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 116s 680ms/step - loss: 9.9825e-05 - accuracy: 1.0000 - val_loss: 0.1007 - val_accuracy: 0.9787 - lr: 6.4000e-09\n",
      "Epoch 84/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 3.5074e-04 - accuracy: 1.0000\n",
      "Epoch 84: val_accuracy did not improve from 0.98094\n",
      "\n",
      "Epoch 84: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 117s 685ms/step - loss: 3.5074e-04 - accuracy: 1.0000 - val_loss: 0.1009 - val_accuracy: 0.9802 - lr: 6.4000e-09\n",
      "Epoch 85/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 2.9102e-04 - accuracy: 1.0000\n",
      "Epoch 85: val_accuracy did not improve from 0.98094\n",
      "\n",
      "Epoch 85: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 117s 684ms/step - loss: 2.9102e-04 - accuracy: 1.0000 - val_loss: 0.0954 - val_accuracy: 0.9743 - lr: 6.4000e-09\n",
      "Epoch 86/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 1.0653e-04 - accuracy: 1.0000\n",
      "Epoch 86: val_accuracy did not improve from 0.98094\n",
      "\n",
      "Epoch 86: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 116s 680ms/step - loss: 1.0653e-04 - accuracy: 1.0000 - val_loss: 0.1136 - val_accuracy: 0.9758 - lr: 6.4000e-09\n",
      "Epoch 87/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 1.4119e-04 - accuracy: 1.0000\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 1.279999928271991e-09.\n",
      "\n",
      "Epoch 87: val_accuracy did not improve from 0.98094\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 116s 681ms/step - loss: 1.4119e-04 - accuracy: 1.0000 - val_loss: 0.1090 - val_accuracy: 0.9751 - lr: 6.4000e-09\n",
      "Epoch 88/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 1.2647e-04 - accuracy: 1.0000\n",
      "Epoch 88: val_accuracy did not improve from 0.98094\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 117s 684ms/step - loss: 1.2647e-04 - accuracy: 1.0000 - val_loss: 0.0994 - val_accuracy: 0.9802 - lr: 1.2800e-09\n",
      "Epoch 89/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 1.7257e-04 - accuracy: 1.0000\n",
      "Epoch 89: val_accuracy did not improve from 0.98094\n",
      "\n",
      "Epoch 89: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 116s 680ms/step - loss: 1.7257e-04 - accuracy: 1.0000 - val_loss: 0.1343 - val_accuracy: 0.9773 - lr: 1.2800e-09\n",
      "Epoch 90/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 3.4475e-04 - accuracy: 0.9998\n",
      "Epoch 90: val_accuracy did not improve from 0.98094\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 116s 675ms/step - loss: 3.4475e-04 - accuracy: 0.9998 - val_loss: 0.1024 - val_accuracy: 0.9780 - lr: 1.2800e-09\n",
      "Epoch 91/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 1.6415e-04 - accuracy: 1.0000\n",
      "Epoch 91: val_accuracy did not improve from 0.98094\n",
      "\n",
      "Epoch 91: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 117s 681ms/step - loss: 1.6415e-04 - accuracy: 1.0000 - val_loss: 0.1119 - val_accuracy: 0.9773 - lr: 1.2800e-09\n",
      "Epoch 92/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 1.7451e-04 - accuracy: 1.0000\n",
      "Epoch 92: val_accuracy did not improve from 0.98094\n",
      "\n",
      "Epoch 92: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 116s 676ms/step - loss: 1.7451e-04 - accuracy: 1.0000 - val_loss: 0.0945 - val_accuracy: 0.9758 - lr: 1.2800e-09\n",
      "Epoch 93/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 9.6906e-05 - accuracy: 1.0000\n",
      "Epoch 93: val_accuracy did not improve from 0.98094\n",
      "\n",
      "Epoch 93: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 117s 682ms/step - loss: 9.6906e-05 - accuracy: 1.0000 - val_loss: 0.1057 - val_accuracy: 0.9765 - lr: 1.2800e-09\n",
      "Epoch 94/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 1.9818e-04 - accuracy: 1.0000\n",
      "Epoch 94: val_accuracy did not improve from 0.98094\n",
      "\n",
      "Epoch 94: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 118s 690ms/step - loss: 1.9818e-04 - accuracy: 1.0000 - val_loss: 0.1218 - val_accuracy: 0.9729 - lr: 1.2800e-09\n",
      "Epoch 95/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 1.0076e-04 - accuracy: 1.0000\n",
      "Epoch 95: val_accuracy did not improve from 0.98094\n",
      "\n",
      "Epoch 95: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 119s 695ms/step - loss: 1.0076e-04 - accuracy: 1.0000 - val_loss: 0.1152 - val_accuracy: 0.9809 - lr: 1.2800e-09\n",
      "Epoch 96/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 1.4249e-04 - accuracy: 1.0000\n",
      "Epoch 96: val_accuracy did not improve from 0.98094\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 122s 716ms/step - loss: 1.4249e-04 - accuracy: 1.0000 - val_loss: 0.1193 - val_accuracy: 0.9773 - lr: 1.2800e-09\n",
      "Epoch 97/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 1.2029e-04 - accuracy: 1.0000\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 1e-09.\n",
      "\n",
      "Epoch 97: val_accuracy did not improve from 0.98094\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 119s 696ms/step - loss: 1.2029e-04 - accuracy: 1.0000 - val_loss: 0.1105 - val_accuracy: 0.9721 - lr: 1.2800e-09\n",
      "Epoch 98/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 1.4023e-04 - accuracy: 1.0000\n",
      "Epoch 98: val_accuracy did not improve from 0.98094\n",
      "\n",
      "Epoch 98: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 121s 704ms/step - loss: 1.4023e-04 - accuracy: 1.0000 - val_loss: 0.1240 - val_accuracy: 0.9758 - lr: 1.0000e-09\n",
      "Epoch 99/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 1.1154e-04 - accuracy: 1.0000\n",
      "Epoch 99: val_accuracy did not improve from 0.98094\n",
      "\n",
      "Epoch 99: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 120s 700ms/step - loss: 1.1154e-04 - accuracy: 1.0000 - val_loss: 0.1246 - val_accuracy: 0.9736 - lr: 1.0000e-09\n",
      "Epoch 100/100\n",
      "171/171 [==============================] - ETA: 0s - loss: 1.9194e-04 - accuracy: 1.0000\n",
      "Epoch 100: val_accuracy did not improve from 0.98094\n",
      "\n",
      "Epoch 100: val_loss did not improve from 0.09096\n",
      "171/171 [==============================] - 119s 699ms/step - loss: 1.9194e-04 - accuracy: 1.0000 - val_loss: 0.1035 - val_accuracy: 0.9795 - lr: 1.0000e-09\n"
     ]
    }
   ],
   "source": [
    "# EntraÃ®ner le modÃ¨le\n",
    "hist = model.fit(train_dataset,\n",
    "                 epochs=100,\n",
    "                 validation_data=val_dataset,\n",
    "                 callbacks=[reduce_lr, ckpt_best_acc, ckpt_best_loss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.history['lr'] = np.array(hist.history['lr']).tolist()\n",
    "save_jsonfile('models/MobileNetV2_history.json', hist.history, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "history = read_jsonfile('models/MobileNetV2_history.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 6s 105ms/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from src import inference, create_test_dataset\n",
    "from sklearn import metrics\n",
    "\n",
    "model = load_model(\"models/MobileNetV2_ckpt_best_loss.keras\")\n",
    "\n",
    "df = pd.read_csv('data/processed/DL_test.csv')\n",
    "X_test = df['image_path'].values\n",
    "Y_test = df['category'].values\n",
    "test_dataset = create_test_dataset(X_test, Y_test)\n",
    "\n",
    "pred = model.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98       235\n",
      "           1       0.97      0.96      0.97       243\n",
      "           2       0.95      0.97      0.96       362\n",
      "           3       0.99      1.00      1.00       305\n",
      "           4       0.99      1.00      0.99       298\n",
      "           5       0.99      0.97      0.98       261\n",
      "\n",
      "    accuracy                           0.98      1704\n",
      "   macro avg       0.98      0.98      0.98      1704\n",
      "weighted avg       0.98      0.98      0.98      1704\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(Y_test, pred.argmax(axis = 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 560ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'invoice'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pth = \"./data/raw/data_02/images/img_0000049.jpg\"\n",
    "result = inference(model, pth)\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
