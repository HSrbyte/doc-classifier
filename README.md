# doc-classifier
Projet de classification de documents dans le cadre de la formation DataScientest (novembre 2023). Le projet est divis√© en plusieurs √©tapes, chacune document√©e dans plusieurs notebooks :

### 1 - Analyse exploratoire des datasets (notebooks 00 √† 05):
Cette √©tape inclut la compr√©hension et l'analyse initiale des jeux de donn√©es, avec des visualisations et des statistiques descriptives pour pr√©parer les √©tapes suivantes.

### 2 - Premi√®re mod√©lisation : Classification des donn√©es textuelles (notebooks 06 √† 11):
Utilisation de Tesseract pour l'extraction de texte √† partir des documents, suivie d'une classification bas√©e sur les donn√©es textuelles. Les mod√®les d√©velopp√©s dans cette phase sont principalement ax√©s sur le traitement du langage naturel (NLP).

### 3 - Deuxi√®me mod√©lisation : Classification des images (notebooks 12 √† 19):
Application de techniques de Deep Learning pour la classification des documents bas√©e sur les images. Cette √©tape comprend le pr√©traitement des images, la conception des mod√®les de r√©seaux de neurones convolutifs (CNN), et l'√©valuation des performances des mod√®les.


### Organisation des fichiers

- [notebooks/](notebooks/)
Ce dossier contient tous les notebooks d√©taillant les diff√©rentes √©tapes du projet, du nettoyage des donn√©es √† la mod√©lisation finale.

- [reports/](reports/)
Le rapport final du projet se trouve dans ce dossier. Il contient une synth√®se de toutes nos analyses et conclusions.

- [models/](models/)
Ce dossier doit contenir tous les mod√®les pr√©-entra√Æn√©s. Vous pouvez t√©l√©charger tous les mod√®les pr√©-entra√Æn√©s utilis√©s dans ce projet via le lien suivant : [Google Drive](https://drive.google.com/drive/folders/1Nni1RCqoR4cPTvxcwLCgCB0zghz5uBhi?usp=sharing)



## üõ†Ô∏è Installation

T√©l√©charger le projet Git :
```shell
git clone https://github.com/Scientest23/doc-classifier
cd doc-classifier
```

Cr√©er un environnement python :
```shell
# Windows:
python -m venv .venv
.venv\Scripts\activate.bat

# Linux:
python3 -m venv .venv
source .venv/bin/activate
```

Requirements :
```shell
# Update pip:
pip install --update pip

# Install requirements:
pip install -r requirements.txt
```

## üìÑ Datasets

Name | Size | Images | Download
-----|------|--------|-----------
Text extraction for OCR| 33.5 Mo | 520 | [Google Drive](https://drive.google.com/file/d/1w0FhoxyHAjFrWJBQ63JiJFPBsxBEUOVO/view?usp=drive_link)
Projet OCR classification | 203.3 Mo | 1 608 | [Google Drive](https://drive.google.com/file/d/1wDa-pXwdUmEpubo8UjGwQCWzZt9PNZbI/view?usp=drive_link)
RVL-CDIP Dataset (5% of original dataset)| 1.8 Go | 20 000 | [Google Drive](https://drive.google.com/file/d/13V-hUMebr5PZjqNcuwxUPlB6u7lEq_gB/view?usp=drive_link)
PRADO | 139.6 Mo | 1 589 | [Google Drive](https://drive.google.com/file/d/1Seii3yeWKoc4f9eUNcgAwDtFleO0yjUm/view?usp=drive_link)
RVL-CDIP Dataset | 38.8 Go | 400 000 | [Hugging Face](https://huggingface.co/datasets/aharley/rvl_cdip/resolve/main/data/rvl-cdip.tar.gz?download=true)


To extract and import datasets, see the notebook: [00-hryniewski-download-datasets.ipynb](notebooks/00-hryniewski-download-datasets.ipynb)


## üôå Authors:
- Bryan Fernandez
- Ayoub Benkou
- Achraf Asri
- Daniel Hryniewski